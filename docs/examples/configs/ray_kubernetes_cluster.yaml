# For most use-cases, it makes sense to schedule one Ray pod per Kubernetes node.

# Optimal resource allocation will depend on your Kubernetes infrastructure and might
# require some experimentation.
apiVersion: ray.io/v1alpha1
kind: RayCluster
metadata:
  labels:
    controller-tools.k8s.io: "1.0"
    # An unique identifier for the head node and workers of this cluster.
  name: raycluster-autoscaler
  namespace: default
spec:
  rayVersion: "1.13.0"
  enableInTreeAutoscaling: True
  ######################headGroupSpecs#################################
  # head group template and specs, (perhaps 'group' is not needed in the name)
  headGroupSpec:
    # Kubernetes Service Type, valid values are 'ClusterIP', 'NodePort' and 'LoadBalancer'
    serviceType: ClusterIP
    # for the head group, replicas should always be 1.
    # headGroupSpec.replicas is deprecated in KubeRay >= 0.3.0.
    # logical group name, for this called head-group, also can be functional
    # pod type head or worker
    # rayNodeType: head # Not needed since it is under the headgroup
    # the following params are used to complete the ray start: ray start --head --block --redis-port=6379 ...
    rayStartParams:
      port: "6379"
      dashboard-host: "0.0.0.0"
      block: "true"

    #pod template
    template:
      metadata:
        labels:
          # custom labels. NOTE: do not define custom labels start with `raycluster.`, they may be used in controller.
          # Refer to https://kubernetes.io/docs/concepts/overview/working-with-objects/labels/
          rayCluster: raycluster-sample # will be injected if missing
          rayNodeType: head # will be injected if missing, must be head or wroker
          groupName: headgroup # will be injected if missing
        # annotations for pod
        annotations:
          key: value
      spec:
        containers:
          - name: ray-head
            image: public.ecr.aws/i7t1s5i1/fedgraph:lp
            # imagePullPolicy: Always
            # Optimal resource allocation will depend on your Kubernetes infrastructure and might
            # require some experimentation.
            # Setting requests=limits is recommended with Ray. K8s limits are used for Ray-internal
            # resource accounting. K8s requests are not used by Ray.
            resources:
              limits:
                cpu: "30"
                memory: "100Gi"
                # nvidia.com/gpu: "1"

              requests:
                cpu: "30"
                memory: "100Gi"
                # nvidia.com/gpu: "1"
            env:
              - name: CPU_REQUEST
                valueFrom:
                  resourceFieldRef:
                    containerName: ray-head
                    resource: requests.cpu
              - name: CPU_LIMITS
                valueFrom:
                  resourceFieldRef:
                    containerName: ray-head
                    resource: limits.cpu
              - name: MEMORY_LIMITS
                valueFrom:
                  resourceFieldRef:
                    containerName: ray-head
                    resource: limits.memory
              - name: MEMORY_REQUESTS
                valueFrom:
                  resourceFieldRef:
                    containerName: ray-head
                    resource: requests.memory
              - name: MY_POD_IP
                valueFrom:
                  fieldRef:
                    fieldPath: status.podIP
              - name: RAY_GRAFANA_IFRAME_HOST
                value: http://127.0.0.1:3000
              - name: RAY_GRAFANA_HOST
                value: http://prometheus-grafana.prometheus-system.svc:80
              - name: RAY_PROMETHEUS_HOST
                value: http://prometheus-kube-prometheus-prometheus.prometheus-system.svc:9090
            ports:
              - containerPort: 6379
                name: gcs
              - containerPort: 8265
                name: dashboard
              - containerPort: 10001
                name: client
              - containerPort: 8080
                name: metrics
              - containerPort: 8000
                name: serve
              - containerPort: 44217
                name: as-metrics # autoscaler
              - containerPort: 44227
                name: dash-metrics # dashboard
            lifecycle:
              preStop:
                exec:
                  command: ["/bin/sh", "-c", "ray stop"]
  workerGroupSpecs:
    # the pod replicas in this group typed worker
    - replicas: 5
      minReplicas: 5
      maxReplicas: 5
      # logical group name, for this called large-group, also can be functional
      groupName: large-group
      # if worker pods need to be added, we can simply increment the replicas
      # if worker pods need to be removed, we decrement the replicas, and populate the podsToDelete list
      # the operator will remove pods from the list until the number of replicas is satisfied
      # when a pod is confirmed to be deleted, its name will be removed from the list below
      #scaleStrategy:
      #  workersToDelete:
      #  - raycluster-complete-worker-small-group-bdtwh
      #  - raycluster-complete-worker-small-group-hv457
      #  - raycluster-complete-worker-small-group-k8tj7
      # the following params are used to complete the ray start: ray start --block --node-ip-address= ...
      rayStartParams:
        block: "true"
      #pod template
      template:
        metadata:
          labels:
            rayCluster: raycluster-complete # will be injected if missing
            rayNodeType: worker # will be injected if missing
            groupName: small-group # will be injected if missing
          # annotations for pod
          annotations:
            key: value
        spec:

          containers:
            - name: machine-learning # must consist of lower case alphanumeric characters or '-', and must start and end with an alphanumeric character (e.g. 'my-name',  or '123-abc'
              image: public.ecr.aws/i7t1s5i1/fedgraph:lp
              # imagePullPolicy: Always
              # Setting requests=limits is recommended with Ray. K8s limits are used for Ray-internal
              # resource accounting. K8s requests are not used by Ray.
              resources:
                limits:
                  cpu: "12"
                  memory: "50Gi"
                  # nvidia.com/gpu: "1"
                requests:
                  cpu: "12"
                  memory: "50Gi"
                  # nvidia.com/gpu: "1"
              # environment variables to set in the container.Optional.
              # Refer to https://kubernetes.io/docs/tasks/inject-data-application/define-environment-variable-container/
              env:
                - name: RAY_DISABLE_DOCKER_CPU_WARNING
                  value: "1"
                - name: TYPE
                  value: "worker"
                - name: CPU_REQUEST
                  valueFrom:
                    resourceFieldRef:
                      containerName: machine-learning
                      resource: requests.cpu
                - name: CPU_LIMITS
                  valueFrom:
                    resourceFieldRef:
                      containerName: machine-learning
                      resource: limits.cpu
                - name: MEMORY_LIMITS
                  valueFrom:
                    resourceFieldRef:
                      containerName: machine-learning
                      resource: limits.memory
                - name: MEMORY_REQUESTS
                  valueFrom:
                    resourceFieldRef:
                      containerName: machine-learning
                      resource: requests.memory
                - name: MY_POD_NAME
                  valueFrom:
                    fieldRef:
                      fieldPath: metadata.name
                - name: MY_POD_IP
                  valueFrom:
                    fieldRef:
                      fieldPath: status.podIP
              ports:
                - containerPort: 80
              lifecycle:
                preStop:
                  exec:
                    command: ["/bin/sh", "-c", "ray stop"]
              # use volumeMounts.Optional.
              # Refer to https://kubernetes.io/docs/concepts/storage/volumes/
              volumeMounts:
                - mountPath: /var/log
                  name: log-volume
          initContainers:
            # the env var $RAY_IP is set by the operator if missing, with the value of the head service name
            - name: init-myservice
              image: busybox:1.28
              # Change the cluster postfix if you don't have a default setting
              command:
                [
                  "sh",
                  "-c",
                  "until nslookup $RAY_IP.$(cat /var/run/secrets/kubernetes.io/serviceaccount/namespace).svc.cluster.local; do echo waiting for myservice; sleep 2; done",
                ]
          # use volumes
          # Refer to https://kubernetes.io/docs/concepts/storage/volumes/
          volumes:
            - name: log-volume
              emptyDir: {}
