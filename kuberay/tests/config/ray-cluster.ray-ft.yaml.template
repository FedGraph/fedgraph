kind: ConfigMap
apiVersion: v1
metadata:
  name: redis-config
  labels:
    app: redis
data:
  redis.conf: |-
    dir /data
    port 6379
    bind 0.0.0.0
    appendonly yes
    protected-mode no
    requirepass 5241590000000000
    pidfile /data/redis-6379.pid
---
apiVersion: v1
kind: Service
metadata:
  name: redis
  labels:
    app: redis
spec:
  type: ClusterIP
  ports:
    - name: redis
      port: 6379
  selector:
    app: redis
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: redis
  labels:
    app: redis
spec:
  replicas: 1
  selector:
    matchLabels:
      app: redis
  template:
    metadata:
      labels:
        app: redis
    spec:
      containers:
        - name: redis
          image: redis:5.0.8
          command:
            - "sh"
            - "-c"
            - "redis-server /usr/local/etc/redis/redis.conf"
          ports:
            - containerPort: 6379
          volumeMounts:
            - name: config
              mountPath: /usr/local/etc/redis/redis.conf
              subPath: redis.conf
      volumes:
        - name: config
          configMap:
            name: redis-config
---
apiVersion: ray.io/v1
kind: RayCluster
metadata:
  labels:
    controller-tools.k8s.io: "1.0"
  annotations:
    ray.io/ft-enabled: "true" # enable Ray GCS FT
  name: raycluster-external-redis
spec:
  rayVersion: '$ray_version'
  headGroupSpec:
    rayStartParams:
      dashboard-host: "0.0.0.0"
      num-cpus: "0"
      redis-password: "5241590000000000"
    #pod template
    template:
      spec:
        containers:
          - name: ray-head
            image: $ray_image
            env:
              # RAY_REDIS_ADDRESS can force ray to use external redis
              - name: RAY_REDIS_ADDRESS
                value: redis:6379
              - name: RAY_gcs_rpc_server_reconnect_timeout_s
                value: "20"
            ports:
              - containerPort: 6379
                name: redis
              - containerPort: 8265
                name: dashboard
              - containerPort: 10001
                name: client
            volumeMounts:
              - mountPath: /home/ray/samples
                name: test-script-configmap
        volumes:
          - name: test-script-configmap
            configMap:
              name: test-script
              # An array of keys from the ConfigMap to create as files
              items:
                - key: test_ray_serve_1.py
                  path: test_ray_serve_1.py
                - key: test_ray_serve_2.py
                  path: test_ray_serve_2.py
                - key: test_detached_actor_1.py
                  path: test_detached_actor_1.py
                - key: test_detached_actor_2.py
                  path: test_detached_actor_2.py
  workerGroupSpecs:
    # the pod replicas in this group typed worker
    - replicas: 1
      minReplicas: 1
      maxReplicas: 2
      # logical group name, for this called small-group, also can be functional
      groupName: small-group
      rayStartParams: {}
      #pod template
      template:
        spec:
          containers:
            - name: ray-worker # must consist of lower case alphanumeric characters or '-', and must start and end with an alphanumeric character (e.g. 'my-name',  or '123-abc'
              image: $ray_image
              env:
                - name: RAY_gcs_rpc_server_reconnect_timeout_s
                  value: "120"
              resources:
                limits:
                  cpu: "1"
                requests:
                  cpu: "200m"
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: test-script
data:
  test_ray_serve_1.py: |
    import ray
    from ray import serve
    from ray.util.state import list_nodes
    import requests
    import time

    # 0: Wait until only 1 head Pod is alive
    print("Wait until only 1 head Pod is alive", flush=True)
    for i in range(90):
      nodes = list_nodes()
      num_alive_heads = 0
      for node in nodes:
          if node.is_head_node and node.state == "ALIVE":
              num_alive_heads += 1
      print(f"iter {i}: {num_alive_heads} head nodes are alive.", flush=True)
      if num_alive_heads == 1:
          break
      time.sleep(1)


    # 1: Define a Ray Serve model.
    @serve.deployment
    class MyModelDeployment:
        def __init__(self, msg: str):
            self._msg = msg

        def __call__(self):
            return self._msg
    app = MyModelDeployment.bind(msg="Hello world!")

    # 2: Deploy the model.
    serve.run(app)
    # 3: Query the deployment and print the result.
    resp = requests.get("http://localhost:8000/")
    assert(resp.status_code == 200)
    print(resp.status_code)
    print(resp.text)
    assert(resp.text == "Hello world!")

  test_ray_serve_2.py: |
    import requests
    import time

    def retry_with_timeout(func, timeout=90):
        err = None
        for i in range(timeout):
            try:
                print(f"retry iter: {i}")
                return func()
            except BaseException as e:
                err = e
            finally:
                time.sleep(1)
        raise err

    def send_req():
        response = requests.get('http://127.0.0.1:8000', timeout=10)
        print('Response status code:', response.status_code)
        print('Response headers:', response.headers)
        print('Response content:', response.text)
        assert(response.text == "Hello world!")

    retry_with_timeout(send_req, 180)

  test_detached_actor_1.py: |
    import ray
    import sys

    ray.init(namespace=sys.argv[1])

    @ray.remote
    class TestCounter:
        def __init__(self):
            self.value = 0

        def increment(self):
            self.value += 1
            return self.value

    tc = TestCounter.options(name="testCounter", lifetime="detached", max_restarts=-1).remote()
    val1 = ray.get(tc.increment.remote())
    val2 = ray.get(tc.increment.remote())
    print(f"val1: {val1}, val2: {val2}")

    assert(val1 == 1)
    assert(val2 == 2)

  test_detached_actor_2.py: |
    import ray
    import time
    import sys

    def retry_with_timeout(func, timeout=90):
        err = None
        start = time.time()
        i = 0
        while time.time() - start <= timeout:
            try:
                print(f"retry iter: {i}", flush=True)
                i += 1
                return func()
            except BaseException as e:
                err = e
            finally:
                time.sleep(1)
        raise err

    def get_detached_actor():
        return ray.get_actor("testCounter")

    # Try to connect to Ray cluster.
    print("Try to connect to Ray cluster.", flush=True)
    retry_with_timeout(lambda: ray.init(address='ray://127.0.0.1:10001', namespace=sys.argv[1]), timeout = 180)

    # Get TestCounter actor
    print("Get TestCounter actor.", flush=True)
    tc = retry_with_timeout(get_detached_actor)

    print("Try to call remote function \'increment\'.", flush=True)
    val = retry_with_timeout(lambda: ray.get(tc.increment.remote()))
    print(f"val: {val}", flush=True)

    assert(val == int(sys.argv[2]))
